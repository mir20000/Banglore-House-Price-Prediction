# -*- coding: utf-8 -*-
"""Bengaluru_House_price.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pCK_Mx02B581TPu8rpeNdkVaSBQNvo_b
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
import pickle 
# %matplotlib inline

df = pd.read_csv('Bengaluru_House_Data.csv')
df

df.isnull().sum()

df = df.drop(['area_type','society','balcony','availability'],axis=1)
df.head()

df.bath = df.bath.fillna(df.bath.median())
df = df.dropna()
df.isnull().sum()

df

df['size'].unique()

df['bedrooms'] = df['size'].apply(lambda x: int(x.split(' ')[0]))
df

df = df.drop(['size'],axis=1)
df

len(df['location'].unique())
new_df = df

df.location = df.location.apply(lambda x: x.strip())
location_nums = df.groupby('location')['location'].agg('count').sort_values(ascending=False)
len(location_nums[location_nums<=10])

df.location = df.location.apply(lambda x: 'other' if x in location_nums[location_nums<=10] else x )
len(df.location.unique())

def sqft_to_num(x):
    tokens = x.split('-')
    if len(tokens) == 2:
        return (float(tokens[0]) + float(tokens[1]))/2
    try:
        return float(x)
    except:
        return None

df['total_sqft'] = df['total_sqft'].apply(sqft_to_num)
df

df['price_per_sqft'] = df['price']*100000/df['total_sqft']
df

df['price_per_sqft'].describe()

df_new = df[~(df.total_sqft/df.bedrooms<300)]
len(df_new)

import seaborn as sns
sns.heatmap(df_new[['location','total_sqft','bath','bedrooms','price_per_sqft', "price"]].corr(),cmap="coolwarm", annot=True)

from sklearn.preprocessing import LabelEncoder
lben = LabelEncoder()

dflben = df_new
dflben.location = lben.fit_transform(dflben.location)
dflben

int(lben.transform(['Electronic City Phase II']))

dflben = dflben.dropna()
dflben.isnull().sum()

x = dflben.drop(['price'],axis=1)
y = dflben.price

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split (x,y,test_size=0.2,random_state=10)

reg =LinearRegression()
reg.fit(x_train,y_train)

reg.score(x_test,y_test)

from sklearn.ensemble import GradientBoostingRegressor

params = {'n_estimators': 500, 'max_depth': 4, 'min_samples_split': 2,
          'learning_rate': 0.01, 'loss': 'ls'}

gbr = GradientBoostingRegressor(n_estimators = 700, max_depth = 3 , min_samples_split = 2,learning_rate = 0.01, loss = 'ls')
gbr.fit(x_train, y_train)
gbr.score(x_test,y_test)

reg.predict([[60,2600.0,5.0,4,4615.384615]])

pickle.dump(lben,open('lben.pkl','wb'))
pickle.dump(reg,open('reg_model.pkl','wb'))
pickle.dump(gbr,open('gbr_model.pkl','wb'))